#  Отслеживание людей, оценка позы и анализ поведения на видео

Этот проект выполняет обнаружение, отслеживание и анализ поз человека на видео с использованием моделей YOLO12 и DeepSORT.

---

## Возможности

* Обнаружение людей с помощью YOLO12
* Мультиобъектное отслеживание с помощью DeepSORT
* Оценка позы на базе YOLO11-pose
* Анализ поведения (например, сидит, жестикулирует)
* Сохранение данных по кадрам в структурированном JSON
* Вывод видео с рамками, ID и скелетами поз

---

## Требования

Установите зависимости:

```bash
pip install ultralytics
pip install opencv-python
pip install deep_sort_realtime
pip install torch torchvision 

```

---

## Структура проекта

```
├── yolo12x.pt                # Модель YOLO12 для детекции людей
├── yolo11x-pose.pt           # Модель YOLO11-pose для оценки поз
├── video.mp4                 # Входное видео
├── tracked_output.mp4        # Выходное видео с трекингом и позами
├── track_data.json           # Данные трекинга по кадрам
├── main.py                   # Основной скрипт
├── README.md                 # Этот файл
```

---

## Как запустить

1. Поместите модели (yolo12x.pt, yolo11x-pose.pt) и видео (video.mp4) в рабочую директорию.

2. Запустите основной скрипт:

```bash
python main.py
```

3. После выполнения появятся:

* tracked_output.mp4 — видео с трекингом и наложением поз
* track_data.json — подробные данные по каждому кадру

---

## ️ Конфигурации запуска моделей и производительность

Таблица с основными конфигурациями запуска моделей YOLO12 и YOLO11-pose в рамках проекта. В таблице указаны размеры входных изображений, используемое устройство (CPU/GPU) и примерное время обработки одного кадра.

| Конфигурация                    | Детекция YOLO          | Поза YOLO                  | Устройство | Время на кадр (примерно) |
| ------------------------------- | ---------------------- | -------------------------- | ---------- | ------------------------ |
| 1. Быстрое обнаружение + поза   | yolo12x.pt  imgsz=640  | yolo11x-pose.pt  imgsz=320 | CUDA       | \~90–120 мс              |
| 2. Сбалансированный режим       | yolo12x.pt  imgsz=1280 | yolo11x-pose.pt  imgsz=640 | CUDA       | \~150–220 мс             |
| 3. Высокая точность             | yolo12x.pt  imgsz=1280 | yolo11x-pose.pt  imgsz=960 | CUDA       | \~300–400 мс             |
| 4. CPU-режим (оптимизированный) | yolo12x.pt  imgsz=640  | yolo11x-pose.pt  imgsz=320 | CPU        | \~1.5–2.5 сек            |
| 5. CPU + высокая точность       | yolo12x.pt  imgsz=1280 | yolo11x-pose.pt  imgsz=640 | CPU        | \~3–5 сек                |
---
## Пример выходного JSON

```json
"frame_00012": {
  "timestamp": 0.4,
  "people": [
    {
      "id": 5,
      "bbox": [x1, y1, x2, y2],
      "keypoints": [[x, y], ..., [-1, -1]],
      "flags": {
        "sitting": false,
        "gesturing": true
      }
    }
  ]
}
```

* id: уникальный ID отслеживаемого объекта
* bbox: координаты ограничивающего прямоугольника
* keypoints: список из 17 пар (x, y) (или [-1, -1], если точка не определена)
* flags: флаги поведения


---

## Вывод

На каждом кадре:
* Ограничивающий прямоугольник + ID
* Ключевые точки позы (17 точек тела)
* Скелет (соединения между точками)
* Флаги поведения, вычисленные для каждого человека

---

## Автор

Хечоян Ани — студентка направления ПМИ МГУ
